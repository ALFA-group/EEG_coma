{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "import IPython\n",
    "\n",
    "import similarity_scaling\n",
    "from similarity_scaling import scale_arr\n",
    "\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import utils\n",
    "import readers\n",
    "from readers.similarity_output_reader import SimilarityOutputReader\n",
    "from readers.patient_info import PatientInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the directory containing the similarity output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity_output_dir = '/afs/csail.mit.edu/u/t/tzhan/NFS/script_output/similarity_clip/'\n",
    "# a short tag for the directory, so that saved figures are named with the tag\n",
    "output_dir_tag = 'clip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the required readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarityReader = SimilarityOutputReader(similarity_output_dir)\n",
    "outcomes_path = '../../../../patient_outcome_info/'\n",
    "patientInfo = PatientInfo(outcomes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sims_per_burst_vector(sims, n_bursts, neighbor_size=3):\n",
    "    # takes in flattened matrix of similarities for all n_bursts burst pairs, \n",
    "    # returns array of length n_bursts of summary similarity number for each burst\n",
    "    n_pairs = n_bursts * (n_bursts - 1) / 2\n",
    "    assert(len(sims)==n_pairs), 'npairs {} != len(sims) {}'.format(n_pairs, len(sims))\n",
    "    sims_matrix = np.zeros((n_bursts, n_bursts))\n",
    "    triu_indices = np.triu_indices_from(sims_matrix, k=1)\n",
    "    sims_matrix[triu_indices] = sims\n",
    "    sims_matrix = sims_matrix + sims_matrix.transpose() # make symmetric\n",
    "    sims_per_burst = np.zeros(n_bursts)\n",
    "    for i in range(n_bursts):\n",
    "        js = range(max(0, i-neighbor_size), i) + range(i+1, min(n_bursts, i+1+neighbor_size))\n",
    "        burst_sims = sims_matrix[i][np.array(js)]\n",
    "        sims_per_burst[i] = np.mean(burst_sims)\n",
    "    return sims_per_burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sim_over_time(edf, similarity_fn, min_episode_length, scale_fn, scale_param, neighbor_size):\n",
    "    nsamples = int(patientInfo.get_edf_duration(edf))\n",
    "    edf_sim_over_time = np.zeros(nsamples)\n",
    "    edf_mask = np.ones(nsamples)\n",
    "    episode_to_sims_list = similarityReader.get_similarities(edf, similarity_fn, \n",
    "                                                                     convert_to_np=True, \n",
    "                                                                     min_episode_length=min_episode_length)\n",
    "    episode_to_burst_ranges = similarityReader.get_burst_ranges(edf)\n",
    "    for episode_dict in episode_to_sims_list:\n",
    "        (episode_start_index, episode_end_index) = episode_dict['episode_start_index'], episode_dict['episode_end_index']\n",
    "        sims = episode_dict['similarities']\n",
    "        if len(sims)==0:\n",
    "            continue\n",
    "        sims = scale_arr(sims, similarity_fn, scale_fn, scale_param)\n",
    "        burst_ranges = episode_to_burst_ranges[(episode_start_index, episode_end_index)]\n",
    "        n_bursts = len(burst_ranges)\n",
    "\n",
    "        burst_start_indices = burst_ranges[:, 0]\n",
    "        sims_per_burst_vector = get_sims_per_burst_vector(sims, n_bursts, neighbor_size=neighbor_size)\n",
    "        # sims over time, interpolated from first burst to last burst\n",
    "        interpolate_fn = scipy.interpolate.interp1d(burst_start_indices, sims_per_burst_vector)\n",
    "        min_burst_index, max_burst_index = min(burst_start_indices), max(burst_start_indices)\n",
    "        interpolated_sims_over_time = interpolate_fn(np.arange(min_burst_index, max_burst_index))\n",
    "        edf_sim_over_time[min_burst_index:max_burst_index] = interpolated_sims_over_time\n",
    "        edf_mask[min_burst_index:max_burst_index] = 0\n",
    "    return edf_sim_over_time, edf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sim_over_time_plot(similarity_fn, scale_fn, scale_param, min_episode_length, max_num_hours, ds_rate,\n",
    "                          neighbor_size, outcome_lambda, plot_in_parts):\n",
    "    new_sids = patientInfo.get_all_sids()\n",
    "    num_samples = utils.hour_to_samples(max_num_hours)/ds_rate\n",
    "\n",
    "    sids_used = []\n",
    "    for new_sid in new_sids:\n",
    "        if patientInfo.has_good_outcome(new_sid)==-1:\n",
    "            print('sid without outcome! this is not expected! sid: {}'.format(new_sid))\n",
    "            continue\n",
    "        if not outcome_lambda(new_sid):\n",
    "            continue\n",
    "        sids_used.append(new_sid)\n",
    "\n",
    "#    sids_used = sids_used[:20]\n",
    "\n",
    "    sim_over_time_matrix = np.zeros((len(sids_used), num_samples))\n",
    "    masks = np.ones((len(sids_used), num_samples))\n",
    "    sim_iter_num = 0\n",
    "\n",
    "    sids_with_sims = []\n",
    "    for i, new_sid in enumerate(sids_used):\n",
    "        print(i, new_sid, ' out of ', len(sids_used))\n",
    "        edfs_and_indices = patientInfo.get_edfs_and_indices(new_sid, max_num_hours=max_num_hours)\n",
    "        patient_sim_over_time = np.zeros(utils.hour_to_samples(max_num_hours))\n",
    "        patient_masks = np.ones(utils.hour_to_samples(max_num_hours))\n",
    "        for edf_num, (edf, start_index, end_index) in enumerate(edfs_and_indices):\n",
    "            edf_sim_over_time, edf_mask = get_sim_over_time(edf, similarity_fn, min_episode_length, scale_fn, scale_param, neighbor_size)\n",
    "            patient_sim_over_time[start_index:end_index] = edf_sim_over_time[:(end_index-start_index)]\n",
    "            patient_masks[start_index:end_index] = edf_mask[:(end_index-start_index)]\n",
    "        if not np.all(patient_masks==1):\n",
    "            # all masked, no actual data, so don't do this one.\n",
    "            sim_over_time_matrix[sim_iter_num] = patient_sim_over_time[::ds_rate]\n",
    "            masks[sim_iter_num] = patient_masks[::ds_rate]\n",
    "            sim_iter_num +=1\n",
    "            sids_with_sims.append(new_sid)\n",
    "        IPython.display.clear_output()\n",
    "    masks = masks.astype(bool)\n",
    "    index_in_samples= np.arange(0, utils.hour_to_samples(max_num_hours), ds_rate)\n",
    "    index_in_seconds = index_in_samples/(0.0+utils.sec_to_samples(1))\n",
    "    minutes, seconds = np.divmod(index_in_seconds, 60)\n",
    "    hours, minutes = np.divmod(minutes, 60)\n",
    "    index_formatted = []\n",
    "    for i in range(len(hours)):\n",
    "        hour = int(hours[i])\n",
    "        minute = int(minutes[i])\n",
    "        time = '{}:{:02d}'.format(hour, minute)\n",
    "        index_formatted.append(time)\n",
    "\n",
    "    sim_over_time_matrix = sim_over_time_matrix[0:sim_iter_num, :]\n",
    "    masks = masks[0:sim_iter_num, :]\n",
    "    sim_over_time_df = pd.DataFrame(sim_over_time_matrix, index=sids_with_sims, columns=index_formatted)\n",
    "\n",
    "    num_rows = sim_over_time_df.shape[0]\n",
    "    if plot_in_parts:\n",
    "        ## Make a bunch of plots, of size befitting a pdf\n",
    "        row_start_ind = 0\n",
    "        num_rows_per_plot = 46\n",
    "        plots = []\n",
    "        while row_start_ind < num_rows:\n",
    "            row_end_ind = min(row_start_ind + 45, num_rows)\n",
    "            sim_over_time_df_part = sim_over_time_df[row_start_ind:row_end_ind]\n",
    "            masks_part = masks[row_start_ind:row_end_ind, :]\n",
    "            fig, ax = plt.subplots(figsize=(6*1.39,1.39*(0.5+0.2*sim_over_time_df_part.shape[0])))\n",
    "            heatmap_plot = seaborn.heatmap(sim_over_time_df_part, vmin=0.0, vmax=1.0, cmap=\"YlGnBu\", mask=masks_part, ax=ax)\n",
    "            plots.append(heatmap_plot)\n",
    "            row_start_ind = row_end_ind\n",
    "        return plots\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(6,0.5+0.2*sim_over_time_df.shape[0]))         \n",
    "        heatmap_plot = seaborn.heatmap(sim_over_time_df, cmap=\"YlGnBu\", vmin=0.0, vmax=1.0, mask=masks, ax=ax)\n",
    "        return heatmap_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_heatmap_plot_parts(plots, output_file_name):\n",
    "    for i, plot in enumerate(plots):\n",
    "        plot.figure.savefig('{}_part{}.png'.format(output_file_name, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity_fn = 'xcorr'\n",
    "scale_fn = 'exp'\n",
    "scale_param = 50.0\n",
    "min_episode_length = 30\n",
    "max_num_hours = 72\n",
    "ds_rate = 100\n",
    "neighbor_size = 10\n",
    "target_outcome='bad'\n",
    "plot_in_parts = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create derived parameters from the defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if scale_fn=='exp' and scale_param==50:\n",
    "    scale_tag = '{}_{}'.format(scale_fn, scale_param)\n",
    "else:\n",
    "    scale_tag = scale_fn\n",
    "image_info = '{}_{}'.format(scale_tag, output_dir_tag)\n",
    "if target_outcome=='good':\n",
    "    outcome_lambda = lambda sid: patientInfo.has_good_outcome(sid)\n",
    "else:\n",
    "    outcome_lambda = lambda sid: patientInfo.has_bad_outcome(sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = 'similarity_over_time_{}_{}_{}_{}'.format(target_outcome, similarity_fn, image_info, min_episode_length)\n",
    "heatmap_plot = get_sim_over_time_plot(similarity_fn, scale_fn, scale_param, min_episode_length, max_num_hours, \n",
    "                                      ds_rate, neighbor_size, outcome_lambda, plot_in_parts)\n",
    "save_heatmap_plot_parts(heatmap_plot, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
